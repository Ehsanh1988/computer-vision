{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "voluntary-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('/workspace/detect-me/product_classifier/scripts')\n",
    "from utils import data_loader\n",
    "from pathlib import Path\n",
    "from keras.applications.resnet import preprocess_input as preprocess_input_resnet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input_efficientnet\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_input_densnet\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sorted-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = efficientNetB7 = tf.keras.applications.EfficientNetB7(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# )\n",
    "# len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "powered-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# base_model = tf.keras.applications.ResNet152V2(\n",
    "#                         include_top=False,\n",
    "#                         weights=\"imagenet\",\n",
    "#                         input_tensor=None,\n",
    "#                         input_shape=None,\n",
    "#                         pooling=None,\n",
    "#                         classes=1000,\n",
    "# #                         classifier_activation=\"softmax\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atmospheric-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.applications.ResNet50(\n",
    "#                              include_top=False,\n",
    "#                              weights=\"imagenet\",\n",
    "#                              input_tensor=None,\n",
    "#                              # input_shape=(*self.image_size, 3),\n",
    "#                              pooling=None,\n",
    "#                              classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f503b186-c3df-475d-b25d-d23162609f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.DenseNet121(\n",
    "                            include_top=False,\n",
    "                            weights=\"imagenet\",\n",
    "                            input_tensor=None,\n",
    "                            input_shape=None,\n",
    "                            pooling=None,\n",
    "                            classes=1000,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0768a15-5497-4a17-98e6-decd6e9cd4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.applications.ResNet50V2(\n",
    "#                              include_top=False,\n",
    "#                              weights=\"imagenet\",\n",
    "#                              input_tensor=None,\n",
    "#                              # input_shape=(*self.image_size, 3),\n",
    "#                              pooling=None,\n",
    "#                              classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sustained-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = Path('/workspace/detect-me/product_classifier/data/milk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "batch_size = 16\n",
    "fine_tune_at = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "burning-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len classes_set 339\n",
      "load_with OUT_mixup_generator\n",
      "Found 10113 validated image filenames belonging to 339 classes.\n",
      "Found 2632 validated image filenames belonging to 339 classes.\n",
      "Found 718 validated image filenames belonging to 339 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset =  data_loader.load_data_flow_from_dataframe(\n",
    "            path_to_data / 'train-val',\n",
    "            path_to_data / 'test',\n",
    "            target_image_size=(224,224),\n",
    "            batch_size=batch_size\n",
    ")\n",
    "num_classes = len(dataset['train'].class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hispanic-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(hp):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    # x = self.data_augment(inputs)\n",
    "#     x = preprocess_input_resnet(inputs)\n",
    "    x = preprocess_input_densnet(inputs)\n",
    "#     x = preprocess_input_efficientnet(inputs)\n",
    "    # As previously mentioned, use training=False as our model contains a BatchNormalization layer.\n",
    "    x = base_model(x, training=False)\n",
    "# __________________________________________________________________________    \n",
    "    \n",
    "    if hp.Choice('global_pooling', ['max', 'avg']) == 'max':\n",
    "        x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#     global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "#     x = global_average_layer(x)\n",
    "# __________________________________________________________________________\n",
    "    x = tf.keras.layers.Dropout(\n",
    "            hp.Float('dropout', 0, 0.5, step=0.1, default=0.5))(x)\n",
    "# __________________________________________________________________________\n",
    "    x = tf.keras.layers.Dense(\n",
    "          hp.Int('hidden_size', 512, 1536, step=512, default=num_classes//2),\n",
    "            activation='relu')(x)\n",
    "\n",
    "#     x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dense(num_classes//2, activation='relu')(x)\n",
    "# __________________________________________________________________________\n",
    "    \n",
    "    prediction_layer = tf.keras.layers.Dense(\n",
    "        num_classes, activation='softmax')\n",
    "\n",
    "    outputs = prediction_layer(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    base_model.trainable = True\n",
    "\n",
    "#     for layer in base_model.layers[:hp.Choice('fine_tune', [200, 120, 100, 70,80,60, 50, 30, 0])]:\n",
    "    for layer in base_model.layers[:hp.Choice('fine_tune', [20, 40, 50, 70, 100, 400,])]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print('len(self.model.trainable_variables) ',\n",
    "          len(base_model.trainable_variables))\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=hp.Float('learning_rate', 1e-6, 1e-2, sampling='log'),\n",
    "                                    beta_1=0.9,\n",
    "                                    beta_2=0.999,\n",
    "                                    epsilon=0.1,\n",
    "#                                     epsilon=hp.Float('epsilon_adam', 1e-2, 1, sampling='log'),\n",
    "                                    amsgrad=False,\n",
    "                                    name=\"Adam\",)\n",
    "#     optimizer=tf.keras.optimizers.SGD(lr=hp.Float('learning_rate', 1e-6, 1e-2, sampling='log'),\n",
    "#                                     momentum=0.9,\n",
    "#                                      name=\"SGD\")\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "#                        loss='categorical_crossentropy',\n",
    "                    loss=tf.nn.softmax_cross_entropy_with_logits,\n",
    "                       metrics=['accuracy',\n",
    "                                #                       tf.keras.metrics.AUC(),\n",
    "                                tf.keras.metrics.Precision(),\n",
    "                                tf.keras.metrics.Recall(),\n",
    "                                # tfa.metrics.F1Score(num_classes=num_classes),\n",
    "                                #   tf.keras.metrics.SparseCategoricalCrossentropy() #error\n",
    "                                ],)        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "according-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tuning_model(num_classes, input_shape):\n",
    "#     model = HyperResNet(input_shape=input_shape, classes=num_classes)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "close-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.model.trainable_variables)  347\n"
     ]
    }
   ],
   "source": [
    "project = 'DENSENET'\n",
    "hyperband_tuner = kt.Hyperband(\n",
    "    build,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2,\n",
    "    directory=project,\n",
    "#     max_trials=50,\n",
    "    project_name=f'{project}-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa467f-c6a8-4909-ab96-ab011cc9f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 Complete [00h 13m 48s]\n",
      "val_accuracy: 0.12765957415103912\n",
      "\n",
      "Best val_accuracy So Far: 0.12765957415103912\n",
      "Total elapsed time: 03h 07m 12s\n",
      "\n",
      "Search: Running Trial #22\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "global_pooling    |avg               |avg               \n",
      "dropout           |0.2               |0.2               \n",
      "hidden_size       |1024              |512               \n",
      "fine_tune         |40                |40                \n",
      "learning_rate     |4.1266e-06        |0.0015882         \n",
      "tuner/epochs      |7                 |7                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |1                 |1                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "len(self.model.trainable_variables)  330\n",
      "Epoch 1/7\n",
      "633/633 [==============================] - 126s 185ms/step - loss: 5.8266 - accuracy: 0.0016 - precision: 9.6561e-04 - recall: 3.4730e-04 - val_loss: 5.8264 - val_accuracy: 0.0015 - val_precision: 0.0011 - val_recall: 3.7994e-04\n",
      "Epoch 2/7\n",
      "633/633 [==============================] - 118s 186ms/step - loss: 5.8260 - accuracy: 0.0021 - precision: 0.0023 - recall: 7.7813e-04 - val_loss: 5.8250 - val_accuracy: 0.0015 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/7\n",
      "633/633 [==============================] - 115s 182ms/step - loss: 5.8236 - accuracy: 0.0060 - precision: 0.0013 - recall: 3.9941e-04 - val_loss: 5.8110 - val_accuracy: 0.0384 - val_precision: 0.0031 - val_recall: 7.5988e-04\n",
      "Epoch 4/7\n",
      "633/633 [==============================] - 117s 184ms/step - loss: 5.7991 - accuracy: 0.0436 - precision: 0.0750 - recall: 0.0244 - val_loss: 5.7593 - val_accuracy: 0.0714 - val_precision: 0.1331 - val_recall: 0.0707\n",
      "Epoch 5/7\n",
      "633/633 [==============================] - 116s 183ms/step - loss: 5.7615 - accuracy: 0.0730 - precision: 0.1418 - recall: 0.0709 - val_loss: 5.7585 - val_accuracy: 0.0714 - val_precision: 0.1080 - val_recall: 0.0710\n",
      "Epoch 6/7\n",
      "633/633 [==============================] - 115s 181ms/step - loss: 5.7584 - accuracy: 0.0736 - precision: 0.1227 - recall: 0.0725 - val_loss: 5.7584 - val_accuracy: 0.0714 - val_precision: 0.0984 - val_recall: 0.0710\n",
      "Epoch 7/7\n",
      "375/633 [================>.............] - ETA: 44s - loss: 5.7625 - accuracy: 0.0684 - precision: 0.1071 - recall: 0.0679"
     ]
    }
   ],
   "source": [
    "tuner_result =\\\n",
    "    hyperband_tuner.search(dataset['train'],\n",
    "             validation_data=dataset['validation'],\n",
    "             epochs=15,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "peaceful-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project resnet50_hyperband/resnet50_hyperband-2/oracle.json\n",
      "len(self.model.trainable_variables)  0\n",
      "INFO:tensorflow:Reloading Tuner from resnet50_hyperband/resnet50_hyperband-2/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# project = 'resnet50_baysian'\n",
    "# bayesian_tuner = kt.tuners.BayesianOptimization(\n",
    "#   kt.applications.HyperResNet(include_top=False,input_shape=(224, 224, 3), classes=num_classes),\n",
    "#   objective='val_accuracy',\n",
    "#   directory=project,\n",
    "#   project_name='1',\n",
    "#   max_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "periodic-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.model.trainable_variables)  0\n"
     ]
    }
   ],
   "source": [
    "baysian_tuner0 = kt.tuners.BayesianOptimization(\n",
    "    build,\n",
    "    objective='val_accuracy',\n",
    "    num_initial_points=50,\n",
    "    max_trials=15,\n",
    "    directory=project,\n",
    "    project_name='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "better-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "global_pooling    |avg               |?                 \n",
      "dropout           |0.2               |?                 \n",
      "hidden_size       |1024              |?                 \n",
      "fine_tune         |500               |?                 \n",
      "learning_rate     |0.0096763         |?                 \n",
      "tuner/epochs      |2                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |3                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n",
      "len(self.model.trainable_variables)  0\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  logits and labels must be broadcastable: logits_size=[16,9569] labels_size=[16,336]\n\t [[node softmax_cross_entropy_with_logits_v2/softmax_cross_entropy_with_logits (defined at /workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py:141) ]]\n\t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_35]]\n  (1) Invalid argument:  logits and labels must be broadcastable: logits_size=[16,9569] labels_size=[16,336]\n\t [[node softmax_cross_entropy_with_logits_v2/softmax_cross_entropy_with_logits (defined at /workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py:141) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_27227]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b1cfc8f6ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtuner_result\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     hyperband_tuner.search(dataset['train'],\n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  logits and labels must be broadcastable: logits_size=[16,9569] labels_size=[16,336]\n\t [[node softmax_cross_entropy_with_logits_v2/softmax_cross_entropy_with_logits (defined at /workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py:141) ]]\n\t [[assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_35]]\n  (1) Invalid argument:  logits and labels must be broadcastable: logits_size=[16,9569] labels_size=[16,336]\n\t [[node softmax_cross_entropy_with_logits_v2/softmax_cross_entropy_with_logits (defined at /workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py:141) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_27227]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "tuner_result =\\\n",
    "    hyperband_tuner.search(dataset['train'],\n",
    "             validation_data=dataset['validation'],\n",
    "             epochs=15,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "white-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian_tuner_result =\\\n",
    "#     bayesian_tuner.search(dataset['train'],\n",
    "#              validation_data=dataset['validation'],\n",
    "#              epochs=7,\n",
    "#              callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "certain-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 Complete [00h 03m 31s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.12068965286016464\n",
      "Total elapsed time: 03h 44m 34s\n",
      "\n",
      "Search: Running Trial #64\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "dropout           |0.4               |0.1               \n",
      "hidden_size       |384               |768               \n",
      "fine_tune         |100               |50                \n",
      "learning_rate     |1.0352e-06        |0.00041523        \n",
      "tuner/epochs      |4                 |2                 \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |2                 |3                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "len(self.model.trainable_variables)  90\n",
      "Epoch 1/4\n",
      "588/588 [==============================] - ETA: 0s - loss: 5.8520 - accuracy: 0.0051 - precision: 0.0051 - recall: 0.0051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-518c3411f655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtuner_result\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     hyperband_tuner.search(dataset['train'],\n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner_result =\\\n",
    "    hyperband_tuner.search(dataset['train'],\n",
    "             validation_data=dataset['validation'],\n",
    "             epochs=13,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 Complete [00h 15m 44s]\n",
      "val_accuracy: 0.9147005677223206\n",
      "\n",
      "Best val_accuracy So Far: 0.9219600558280945\n",
      "Total elapsed time: 05h 43m 25s\n",
      "\n",
      "Search: Running Trial #74\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "dropout           |0.1               |0.1               \n",
      "fine_tune         |120               |80                \n",
      "learning_rate     |0.0021141         |0.0002347         \n",
      "tuner/epochs      |30                |10                \n",
      "tuner/initial_e...|10                |4                 \n",
      "tuner/bracket     |2                 |3                 \n",
      "tuner/round       |2                 |2                 \n",
      "tuner/trial_id    |356fe5f26228b9b...|3196a04e3d67bdc...\n",
      "\n",
      "len(self.model.trainable_variables)  66\n",
      "Epoch 11/30\n",
      "588/588 [==============================] - 107s 176ms/step - loss: 2.2592 - accuracy: 0.7242 - precision: 0.9193 - recall: 0.6631 - val_loss: 0.7486 - val_accuracy: 0.9106 - val_precision: 0.9340 - val_recall: 0.8920\n",
      "Epoch 12/30\n",
      "588/588 [==============================] - 103s 175ms/step - loss: 0.3085 - accuracy: 0.9400 - precision: 0.9754 - recall: 0.9272 - val_loss: 0.6914 - val_accuracy: 0.9097 - val_precision: 0.9344 - val_recall: 0.8984\n",
      "Epoch 13/30\n",
      " 11/588 [..............................] - ETA: 1:35 - loss: 0.2758 - accuracy: 0.9428 - precision: 0.9807 - recall: 0.9386"
     ]
    }
   ],
   "source": [
    "tuner_result =\\\n",
    "    tuner.search(dataset['train'],\n",
    "             validation_data=dataset['validation'],\n",
    "             epochs=25,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_models(num_models=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sized-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<kerastuner.engine.hyperparameters.HyperParameters at 0x7fe2395f33a0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "immediate-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bibliographic-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-acquisition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" main.py \"\"\"\n",
    "\n",
    "# import sys;sys.path.append('/workspace')\n",
    "from configs.config import CFG_RESNET, CFG_VGG16\n",
    "from models.classifier import Classifier\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "resnet152v2 = tf.keras.applications.ResNet152V2(\n",
    "                        include_top=False,\n",
    "                        weights=\"imagenet\",\n",
    "                        input_tensor=None,\n",
    "                        input_shape=None,\n",
    "                        pooling=None,\n",
    "                        classes=1000,\n",
    "#                         classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "resnet_model = tf.keras.applications.ResNet50(\n",
    "                             include_top=False,\n",
    "                             weights=\"imagenet\",\n",
    "                             input_tensor=None,\n",
    "                             # input_shape=(*self.image_size, 3),\n",
    "                             pooling=None,\n",
    "                             classes=1000)\n",
    "\n",
    "vgg_model = tf.keras.applications.VGG16(include_top=False,\n",
    "                                  weights='imagenet',\n",
    "                                  classes=1000)\n",
    "# change config\n",
    "# change name_tensorboard as well\n",
    "# change base_model\n",
    "# for compile overwrite config for fine tune by passing desired params \n",
    "# choose to save or not\n",
    "\n",
    "    # change base_model = xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forward-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path ::\n",
      "/workspace/detect-me/product_classifier/saved_models/milk/resnet50\n",
      "tensorboard_logs_path_ ::\n",
      "/workspace/detect-me/product_classifier/saved_models/milk/tensorboard_logs\n",
      "data_path_ ::\n",
      "/workspace/detect-me/product_classifier/data/milk\n",
      "init_done\n",
      "len(base_model.layers) :\n",
      " 175\n",
      "Found 9398 images belonging to 348 classes.\n",
      "Found 2204 images belonging to 348 classes.\n",
      "Found 328 images belonging to 348 classes.\n"
     ]
    }
   ],
   "source": [
    "                \n",
    "train_config = CFG_RESNET\n",
    "base_model = resnet_model    #!!!!!!!!!|O|!!!!!!!!!!\n",
    "# base_model = resnet152v2    #!!!!!!!!!|O|!!!!!!!!!!\n",
    "\n",
    "should_I_save=False\n",
    "freeze_up_to = train_config['train']['fine_tune_at']\n",
    "lr = train_config['train']['opt_lr']\n",
    "batchs = train_config['train']['batch_size']\n",
    "optimizer = train_config['train']['optimizer']['type']\n",
    "epochs = train_config['train']['epochs']\n",
    "dropout = train_config['train']['dropout']\n",
    "base_model_name = train_config['model']['name']\n",
    "desc = 'DEL___348-classes'\n",
    "model_nametag = f'{base_model_name}_Freeze_{freeze_up_to}_lr-{lr}-{optimizer}_epoch-{epochs}-batch-{batchs}_dropout-{dropout}-{desc}'\n",
    "\n",
    "\n",
    "    \n",
    "model = Classifier(cat = 'milk',\n",
    "#                      config =CFG_RESNET,\n",
    "                   config =train_config,\n",
    "                 name_tensorboard=model_nametag,\n",
    "#                      base_model = resnet_model\n",
    "                 base_model = base_model\n",
    "                  )\n",
    "\n",
    "print('len(base_model.layers) :\\n',len(model.base_model.layers))\n",
    "\n",
    "model.load_data()\n",
    "def train(lr):\n",
    "    \"\"\"Builds model, loads data, trains and evaluates\"\"\"\n",
    "\n",
    "    model.build()\n",
    "    model.compile(fine_tune_at=model.fine_tune_at,\n",
    "                            lr=lr)\n",
    "\n",
    "    history = model.train(save=should_I_save,\n",
    "                          save_name=model_nametag)\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.title('lrate='+str(lr), pad=-50)\n",
    "\n",
    "    print('________________________________________________________________________')\n",
    "    print('________________________________________________________________________')\n",
    "    print('________________________________________________________________________')\n",
    "    print('____________________eval on test set____________________________________')\n",
    "    model.evaluate(model.dataset['test'])\n",
    "    print('________________________________________________________________________')\n",
    "    return history\n",
    "\n",
    "def finetune():\n",
    "    finetune = '1000-120-80'\n",
    "    lr = '0.0001----0.00001---0.000002'\n",
    "    epochs = '10----25'\n",
    "    desc = 'DEL_dropout_45__24_apr_TEST'\n",
    "    base_model = 'RESNET50'\n",
    "    model_nametag = f'{base_model}_Finetune_{finetune}_{lr}_n_{epochs}_{desc}'\n",
    "\n",
    "    model = Classifier(cat = 'milk',\n",
    "                    config =CFG_RESNET,\n",
    "                    name_tensorboard=model_nametag,\n",
    "                    base_model = resnet_model)\n",
    "    model.load_data()\n",
    "\n",
    "    \n",
    "    model.build()\n",
    "    ##\n",
    "    model.compile(fine_tune_at=1000, lr=0.0001)\n",
    "    history = model.train(epochs = 10, save=False,)\n",
    "    ##\n",
    "    model.compile(fine_tune_at=120, lr=0.00001)\n",
    "    history1 = model.train(save=False,\n",
    "                    save_name=model_nametag,\n",
    "                    initial_epoch=history.epoch[-1],\n",
    "                    epochs=15)\n",
    "    ##\n",
    "    model.compile(fine_tune_at=80, lr=0.000002)\n",
    "    history2 = model.train(save=False,\n",
    "                    save_name=model_nametag,\n",
    "                    initial_epoch=history1.epoch[-1],\n",
    "                    epochs=30)\n",
    "\n",
    "    print(history2.history.keys())\n",
    "\n",
    "\n",
    "def test():\n",
    "    model = Classifier(cat = 'milk',\n",
    "                    config =CFG_RESNET,\n",
    "                    name_tensorboard=model_nametag,\n",
    "                    base_model = resnet_model)\n",
    "    model.load_data()\n",
    "    print(model.base_model.name)\n",
    "    print(dir(model))\n",
    "\n",
    "    model = Classifier(cat = 'milk',\n",
    "                    config =CFG_RESNET,\n",
    "                    name_tensorboard='TEST_freeze_up_to_zero_lr00005',\n",
    "                    base_model=resnet_model)\n",
    "    model.load_data()\n",
    "    print(model.base_model.name)\n",
    "    print(dir(model))\n",
    "\n",
    "def get_traindata_info():\n",
    "    import numpy as np \n",
    "    import pandas as pd\n",
    "    model = Classifier(cat = 'milk',\n",
    "                config =CFG_VGG16,\n",
    "                name_tensorboard='TEST_freeze_up_to_zero_lr00005',\n",
    "                base_model=vgg_model)\n",
    "    model.load_data()\n",
    "    train_labels = model.dataset['train'].labels\n",
    "    counts = np.unique(train_labels, return_counts=True)\n",
    "    df = pd.DataFrame(counts).T\n",
    "    print(df.shape)\n",
    "    df.to_csv('train_info.csv')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     train()\n",
    "# #     test()\n",
    "# #     finetune()\n",
    "#     # get_traindata_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedicated-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0001, 0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sized-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.model.trainable_variables)  90\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "callbacks ::[<tensorflow.python.keras.callbacks.TensorBoard object at 0x7f7cc46d7280>]\n",
      "Epoch 1/10\n",
      "293/293 [==============================] - 44s 134ms/step - loss: 5.7995 - accuracy: 0.0803 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 5.6433 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: conv4_block2_3_bn/gamma_0 [Op:WriteHistogramSummary]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-be1d598f1ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# fit model and plot learning curves for a learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# show learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f0c4f553b80c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m     34\u001b[0m                             lr=lr)\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     history = model.train(save=should_I_save,\n\u001b[0m\u001b[1;32m     37\u001b[0m                           save_name=model_nametag)\n\u001b[1;32m     38\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/detect-me/product_classifier/models/classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, save, epochs, save_name, initial_epoch, verbose, add_callbacks)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'callbacks ::{cbs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         history = self.model.fit(self.dataset['train'],\n\u001b[0m\u001b[1;32m    244\u001b[0m                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2396\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0mweight_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m             \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, tensor, family, step)\u001b[0m\n\u001b[1;32m    928\u001b[0m         name=scope)\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msummary_writer_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36msummary_writer_function\u001b[0;34m(name, tensor, function, family)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m     op = smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    859\u001b[0m         should_record_summaries(), record, _nothing, name=\"\")\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    850\u001b[0m     with ops.name_scope(name_scope), summary_op_util.summary_scope(\n\u001b[1;32m    851\u001b[0m         name, family, values=[tensor]) as (tag, scope):\n\u001b[0;32m--> 852\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(tag, scope)\u001b[0m\n\u001b[1;32m    921\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;31m# Note the identity to move the tensor to the CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m     return gen_summary_ops.write_histogram_summary(\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0m_summary_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0m_choose_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary\u001b[0;34m(writer, step, tag, values, name)\u001b[0m\n\u001b[1;32m    477\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m       return write_histogram_summary_eager_fallback(\n\u001b[0m\u001b[1;32m    480\u001b[0m           writer, step, tag, values, name=name, ctx=_ctx)\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary_eager_fallback\u001b[0;34m(writer, step, tag, values, name, ctx)\u001b[0m\n\u001b[1;32m    496\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m   _result = _execute.execute(b\"WriteHistogramSummary\", 0, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m    499\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m    500\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: conv4_block2_3_bn/gamma_0 [Op:WriteHistogramSummary]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(learning_rates)):\n",
    "    \t# determine the plot number\n",
    "\tplot_no = 420 + (i+1)\n",
    "\tpyplot.subplot(plot_no)\n",
    "\t# fit model and plot learning curves for a learning rate\n",
    "\ttrain(learning_rates[i])\n",
    "# show learning curves\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "current-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 19 20:17:04 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 25%   42C    P5    32W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adequate-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/detect-me/product_classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chronic-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.basemodel import BaseModel\n",
    "from utils import image_pp, data_loader\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "designing-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = pathlib.Path(\"/workspace/detect-me/product_classifier/data/\")\n",
    "path_to_model=pathlib.Path(\"/workspace/detect-me/product_classifier/saved_models/\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stable-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = tf.keras.applications.ResNet50(\n",
    "                             include_top=False,\n",
    "                             weights=\"imagenet\",\n",
    "                             input_tensor=None,\n",
    "                             # input_shape=(*self.image_size, 3),\n",
    "                             pooling=None,\n",
    "                             classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bulgarian-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224,244\n",
    "# name_tensorboard = name_tensorboard\n",
    "model = None\n",
    "info = None\n",
    "validation_steps = 0\n",
    "train_length = 0\n",
    "steps_per_epoch = 0\n",
    "cat = 'milk'\n",
    "# optimizer = self.config.train.optimizer.type\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "dropout =0.3\n",
    "lr = 0.0001\n",
    "fine_tune_at = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "horizontal-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9398 images belonging to 348 classes.\n",
      "Found 2204 images belonging to 348 classes.\n",
      "Found 328 images belonging to 348 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = data_loader.load_data_flow_from_directory(\n",
    "    path_to_data /cat/ 'train-val',\n",
    "    path_to_data /cat/ 'test',\n",
    "    target_image_size=image_size,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minor-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and model\n",
    "# self.num_classes = self.config.data.num_classes\n",
    "# self.image_size = self.config.data.image_size\n",
    "\n",
    "# path \n",
    "# self.path_to_data = (pathlib.Path(self.config.data.path_to_data) /\n",
    "#                      self.cat)  # images folder separate by classes\n",
    "# self.path_to_save_model = (pathlib.Path(self.config.data.path_to_model) /\n",
    "#                       self.cat /\n",
    "#                       self.base_model.name)  # save model history\n",
    "# self.path_to_tensroboard_log = (pathlib.Path(self.config.data.path_to_model) /\n",
    "#                       self.cat /\n",
    "#                       'tensorboard_logs')\n",
    "\n",
    "# print(f'model_path ::\\n{path_to_save_model}')\n",
    "# print(f'tensorboard_logs_path_ ::\\n{self.path_to_tensroboard_log}')\n",
    "# print(f'data_path_ ::\\n{self.path_to_data}')\n",
    "# print('init_done')\n",
    "\n",
    "\n",
    "def data_augment(inputs):\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            #                   tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "            #                 tf.keras.layers.experimental.preprocessing.RandomFlip('vertical'),\n",
    "            # tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            # tf.keras.layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "            #                   tf.keras.layers.experimental.preprocessing.RandomZoom(0.4),\n",
    "            # tf.keras.layers.experimental.preprocessing.RandomTranslation(\n",
    "                # height_factor=0.2, width_factor=0.2),\n",
    "            image_pp.RandomCutout((220, 40)),\n",
    "            #           tf.keras.layers.experimental.preprocessing.RandomCrop(224,224,),\n",
    "            #         tf.keras.layers.experimental.preprocessing.Rescaling(),\n",
    "        ]\n",
    "    )\n",
    "    return data_augmentation(inputs)\n",
    "    # plot_history %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "def plot_history(history,\n",
    "                 save=False,\n",
    "                 save_path='./train_validation.png'):\n",
    "    print(history.history.keys)\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()), 1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0, 5.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    if save:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print('plot_saved')\n",
    "        print('save_path\\n', save_path)\n",
    "    plt.show()\n",
    "\n",
    "    return plt.gcf()\n",
    "\n",
    "def load_data():\n",
    "    dataset = data_loader.load_data_flow_from_directory(\n",
    "        path_to_data / cat/ 'train-val',\n",
    "        path_to_data /cat/  'test',\n",
    "        target_image_size=image_size,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    # TODO remove it man! seriouslyy . I mean it. NOW!. . . .\n",
    "    try:\n",
    "        assert set(['train', 'test', 'samples', 'class_indices']).issubset(dataset.keys())\n",
    "    except AssertionError:\n",
    "        print('dictionary loaded from util/dataloader is different')\n",
    "    return dataset\n",
    "\n",
    "dataset = load_data()\n",
    "\n",
    "num_classes = dataset['num_classes']\n",
    "\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-raise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(lr):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "# x = self.data_augment(inputs)\n",
    "    x = preprocess_input(inputs)\n",
    "\n",
    "    # As previously mentioned, use training=False as our model contains a BatchNormalization layer.\n",
    "    x = resnet_model(x, training=False)\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    x = global_average_layer(x)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    # x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(self.dropout)(x)\n",
    "    # x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(num_classes//2, activation='relu')(x)\n",
    "\n",
    "    prediction_layer = tf.keras.layers.Dense(\n",
    "        num_classes, activation='softmax')\n",
    "\n",
    "    outputs = prediction_layer(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    resnet_model.trainable = True\n",
    "    for layer in resnet_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print('len(self.model.trainable_variables) ',\n",
    "          len(resnet_model.trainable_variables))\n",
    "\n",
    "    optimizer = 'adam'\n",
    "    print( optimizer.lower())\n",
    "    if  optimizer.lower() == 'adam':\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=lr,\n",
    "                                    beta_1=0.9,\n",
    "                                    beta_2=0.999,\n",
    "                                    epsilon=1e-07,\n",
    "                                    amsgrad=False,\n",
    "                                    name=\"Adam\",)\n",
    "    elif  optimizer.lower() == 'sgd':\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=lr,\n",
    "                                    momentum=0.9,\n",
    "                                     name=\"SGD\")\n",
    "    elif  optimizer.lower() == 'rmsprop':\n",
    "        optimizer=tf.keras.optimizers.RMSprop(lr=lr,\n",
    "                                    rho=0.9,\n",
    "                                    momentum=0.0,\n",
    "                                    epsilon=1e-07,\n",
    "                                    centered=False,\n",
    "                                    name=\"RMSprop\")\n",
    "    elif  optimizer.lower() == 'adadelta':\n",
    "        optimizer=tf.keras.optimizers.Adadelta(\n",
    "                                    learning_rate=lr,\n",
    "                                    rho=0.95,\n",
    "                                    epsilon=1e-07,\n",
    "                                    name=\"Adadelta\",\n",
    "                                     )\n",
    "    else:\n",
    "        raise ValueError('optimizer s :: |.sgd.|.rmsprop.|.adam.|.adadelta.|]')\n",
    "\n",
    "    # if  ob\n",
    "    model.compile(optimizer=optimizer,\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy',\n",
    "                                #                       tf.keras.metrics.AUC(),\n",
    "                                tf.keras.metrics.Precision(),\n",
    "                                tf.keras.metrics.Recall(),\n",
    "                                # tfa.metrics.F1Score(num_classes=num_classes),\n",
    "                                #   tf.keras.metrics.SparseCategoricalCrossentropy() #error\n",
    "                                ],)\n",
    "    print(['*']*100)\n",
    "    print( model.optimizer.get_config())\n",
    "    print(['*']*100)\n",
    "    \n",
    "    cbs= []\n",
    "    lr_callback1 = ReduceLROnPlateau(\n",
    "                        monitor='loss',\n",
    "                        factor=0.1,\n",
    "                        patience=3,\n",
    "                        verbose=1,\n",
    "                        mode='auto',\n",
    "                        epsilon=0.0001,\n",
    "                        cooldown=0,\n",
    "                        min_lr=0)\n",
    "    cbs.append(lr_callback1)\n",
    "    history =  model.fit( dataset['train'],\n",
    "                             batch_size= batch_size,\n",
    "                             epochs=epochs,\n",
    "                             validation_data= dataset['validation'],\n",
    "                             callbacks=cbs,\n",
    "                             verbose=1,\n",
    "                             steps_per_epoch= dataset['samples'] //  batch_size,\n",
    "                             workers=4,\n",
    "                             )\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.title('lrate='+str(lr), pad=-50)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surface-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.model.trainable_variables)  116\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.0008, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/20\n",
      "293/293 [==============================] - 48s 149ms/step - loss: 5.8099 - accuracy: 0.0749 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.6824 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 43s 147ms/step - loss: 5.6585 - accuracy: 0.0812 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.5368 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 43s 147ms/step - loss: 5.5262 - accuracy: 0.0776 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.4094 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 5.4142 - accuracy: 0.0790 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.2978 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 5.3068 - accuracy: 0.0796 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.2004 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 44s 149ms/step - loss: 5.2246 - accuracy: 0.0827 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.1158 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 44s 149ms/step - loss: 5.1511 - accuracy: 0.0814 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 5.0426 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 5.0815 - accuracy: 0.0804 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.9791 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 5.0317 - accuracy: 0.0790 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.9242 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 43s 147ms/step - loss: 4.9818 - accuracy: 0.0825 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.8774 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 43s 146ms/step - loss: 4.9360 - accuracy: 0.0827 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.8372 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 4.9211 - accuracy: 0.0798 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.8033 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 44s 147ms/step - loss: 4.8804 - accuracy: 0.0822 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.7744 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 44s 148ms/step - loss: 4.8606 - accuracy: 0.0779 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.7500 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 44s 149ms/step - loss: 4.8372 - accuracy: 0.0812 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 4.7297 - val_accuracy: 0.0858 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 16/20\n",
      "109/293 [==========>...................] - ETA: 23s - loss: 4.8380 - accuracy: 0.0790 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a9b48e393e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0008\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-dcd6cfa169e1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     history =  model.fit( dataset['train'],\n\u001b[0m\u001b[1;32m     79\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "behind-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.1, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 56s 175ms/step - loss: 4.9956 - accuracy: 0.0755 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 4.6171 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 171ms/step - loss: 4.7766 - accuracy: 0.0813 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 4.6186 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 51s 173ms/step - loss: 4.7793 - accuracy: 0.0824 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 4.6201 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 52s 174ms/step - loss: 4.7974 - accuracy: 0.0785 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 4.6156 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 52s 175ms/step - loss: 4.8057 - accuracy: 0.0756 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 4.6111 - val_accuracy: 0.0858 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.01, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 58s 183ms/step - loss: 5.4653 - accuracy: 0.0790 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 4.7760 - val_accuracy: 0.0858 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 52s 175ms/step - loss: 4.8244 - accuracy: 0.0804 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 4.6394 - val_accuracy: 0.0858 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 52s 176ms/step - loss: 4.7719 - accuracy: 0.0783 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 4.6103 - val_accuracy: 0.0858 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 52s 176ms/step - loss: 4.7464 - accuracy: 0.0808 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 4.5988 - val_accuracy: 0.0858 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 52s 176ms/step - loss: 4.7539 - accuracy: 0.0774 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 4.5924 - val_accuracy: 0.0858 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 57s 178ms/step - loss: 5.7998 - accuracy: 0.0694 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 5.6432 - val_accuracy: 0.0858 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.6112 - accuracy: 0.0823 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 5.4699 - val_accuracy: 0.0858 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 52s 175ms/step - loss: 5.4571 - accuracy: 0.0819 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 5.3232 - val_accuracy: 0.0858 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 53s 179ms/step - loss: 5.3308 - accuracy: 0.0779 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 5.1995 - val_accuracy: 0.0858 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.2184 - accuracy: 0.0824 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 5.0957 - val_accuracy: 0.0858 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 57s 179ms/step - loss: 5.8469 - accuracy: 0.0736 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 5.8299 - val_accuracy: 0.0858 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 172ms/step - loss: 5.8263 - accuracy: 0.0810 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 5.8085 - val_accuracy: 0.0858 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 52s 175ms/step - loss: 5.8059 - accuracy: 0.0834 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 5.7874 - val_accuracy: 0.0858 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 53s 178ms/step - loss: 5.7862 - accuracy: 0.0814 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 5.7667 - val_accuracy: 0.0858 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 51s 172ms/step - loss: 5.7668 - accuracy: 0.0776 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 5.7462 - val_accuracy: 0.0858 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 1e-05, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 58s 180ms/step - loss: 5.8517 - accuracy: 0.0607 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 5.8500 - val_accuracy: 0.0858 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 173ms/step - loss: 5.8496 - accuracy: 0.0798 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 5.8478 - val_accuracy: 0.0858 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 53s 178ms/step - loss: 5.8475 - accuracy: 0.0783 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 5.8456 - val_accuracy: 0.0858 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.8455 - accuracy: 0.0778 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 5.8434 - val_accuracy: 0.0858 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 52s 174ms/step - loss: 5.8434 - accuracy: 0.0805 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 5.8412 - val_accuracy: 0.0858 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 1e-06, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 58s 180ms/step - loss: 5.8521 - accuracy: 0.0741 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 5.8520 - val_accuracy: 0.0858 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.8519 - accuracy: 0.0785 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 5.8518 - val_accuracy: 0.0858 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 52s 176ms/step - loss: 5.8517 - accuracy: 0.0848 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 5.8515 - val_accuracy: 0.0858 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 52s 175ms/step - loss: 5.8515 - accuracy: 0.0790 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 5.8513 - val_accuracy: 0.0858 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.8513 - accuracy: 0.0810 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 5.8511 - val_accuracy: 0.0858 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "len(self.model.trainable_variables)  152\n",
      "adam\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "{'name': 'Adam', 'learning_rate': 1e-07, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "['*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*']\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 57s 179ms/step - loss: 5.8522 - accuracy: 0.0674 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 5.8522 - val_accuracy: 0.0858 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.8522 - accuracy: 0.0810 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 5.8522 - val_accuracy: 0.0858 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 52s 176ms/step - loss: 5.8522 - accuracy: 0.0782 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 5.8521 - val_accuracy: 0.0858 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 51s 173ms/step - loss: 5.8521 - accuracy: 0.0863 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 5.8521 - val_accuracy: 0.0858 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 51s 174ms/step - loss: 5.8521 - accuracy: 0.0772 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 5.8521 - val_accuracy: 0.0858 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create learning curves for different learning rates\n",
    "learning_rates = [1E-1, 1E-2, 1E-3, 1E-4, 1E-5, 1E-6, 1E-7]\n",
    "for i in range(len(learning_rates)):\n",
    "\t# determine the plot number\n",
    "\tplot_no = 420 + (i+1)\n",
    "\tpyplot.subplot(plot_no)\n",
    "\t# fit model and plot learning curves for a learning rate\n",
    "\ttrain(learning_rates[i])\n",
    "# show learning curves\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integrated-republican",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9a1c10f4bbc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_tensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         super().__init__(config,\n\u001b[1;32m      4\u001b[0m                          base_model=base_model)\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseModel' is not defined"
     ]
    }
   ],
   "source": [
    "# # train %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# def train(self,\n",
    "#           save=False,\n",
    "#           epochs=None,\n",
    "#           save_name='no_name',\n",
    "#           initial_epoch=0,\n",
    "#           verbose=1,\n",
    "#           add_callbacks=[]\n",
    "#           ):\n",
    "\n",
    "#     epochs = epochs if epochs else  epochs\n",
    "#     cbs =  callbacks()\n",
    "#     cbs.extend(add_callbacks)\n",
    "#     print(f'callbacks ::{cbs}')\n",
    "#     history =  model.fit( dataset['train'],\n",
    "#                              batch_size= batch_size,\n",
    "#                              epochs=epochs,\n",
    "#                              initial_epoch=initial_epoch,\n",
    "#                              validation_data= dataset['validation'],\n",
    "#                              callbacks=cbs,\n",
    "#                              verbose=verbose,\n",
    "#                              steps_per_epoch= dataset['samples'] //  batch_size,\n",
    "#                              workers=4,\n",
    "#                              )\n",
    "\n",
    "#     if save:\n",
    "#         DIR =  path_to_save_model / save_name\n",
    "#         if not os.path.exists(DIR):\n",
    "#             os.makedirs(DIR)\n",
    "#          model.save(DIR)\n",
    "#         plot =  plot_history(history, save=True,\n",
    "#                                  save_path=DIR / 'cross_val.png')\n",
    "#         # TODO function history to pandas dataftame\n",
    "#         mapping =  dataset['class_indices']\n",
    "#         mapping = pd.DataFrame.from_dict(mapping, orient='index')\n",
    "#         mapping.columns = ['code']\n",
    "#         mapping.index.name = 'vms'\n",
    "#         mapping.to_csv(DIR /'vms_code_mapping.csv')\n",
    "#         print('saved')\n",
    "#     else:\n",
    "#         plot =  plot_history(history, save=False)\n",
    "\n",
    "#     return history\n",
    "#     # evaluate %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "#     def evaluate(self, test_data):\n",
    "#          model.evaluate(\n",
    "#             test_data,\n",
    "#             batch_size=None,\n",
    "#             verbose=1,\n",
    "#             sample_weight=None,\n",
    "#             steps=None,\n",
    "#             callbacks=None,\n",
    "#             max_queue_size=10,\n",
    "#             workers=1,\n",
    "#             use_multiprocessing=False,\n",
    "#             return_dict=False,\n",
    "#         )\n",
    "#     # predict %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "#     def predict(self, image):\n",
    "#         return  model.predict(image)\n",
    "#     # callbacks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "#     @staticmethod\n",
    "#     def lr_scheduler(epoch, lr):\n",
    "#         if epoch < 10:\n",
    "#             return lr\n",
    "#         else:\n",
    "#             return lr * tf.math.exp(-0.1)\n",
    "\n",
    "#     def callbacks(self,):\n",
    "\n",
    "\n",
    "#         lr_callback = LearningRateScheduler( lr_scheduler)\n",
    "\n",
    "#         tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "#                         log_dir=str( path_to_tensroboard_log/  name_tensorboard),\n",
    "#                         histogram_freq=2,\n",
    "#                         write_graph=False,\n",
    "#                         write_images=True,\n",
    "#                         update_freq=\"epoch\",\n",
    "#                         profile_batch=2,\n",
    "#                         embeddings_freq=0,\n",
    "#                         embeddings_metadata=None,)\n",
    "#         save_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#                         str( path_to_save_model /\n",
    "#                                 'checkpoints' /\n",
    "#                                 f'{ name_tensorboard}' /\n",
    "#                                 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "#                         monitor='val_loss',\n",
    "#                         verbose=0,\n",
    "#                         save_best_only=True,\n",
    "#                         save_weights_only=False,\n",
    "#                         mode='auto',\n",
    "#                         save_freq='epoch',\n",
    "#                         options=None)\n",
    "#         return [\n",
    "#             lr_callback,\n",
    "#             tensorboard_callback,\n",
    "#             # save_checkpoint_callback\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-study",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
